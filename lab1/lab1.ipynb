{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "## Step 1 Naive Bayes\n",
    "### Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use train data: d:\\Windows\\Documents\\Code\\conda\\machine-learning-lab\\lab1\\train.csv\n",
      "Use test  data: d:\\Windows\\Documents\\Code\\conda\\machine-learning-lab\\lab1\\train.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "PATH_ROOT = os.getcwd()\n",
    "PATH_TRAIN = os.path.join(PATH_ROOT, 'train.csv')\n",
    "PATH_TEST = os.path.join(PATH_ROOT, 'test.csv')\n",
    "\n",
    "print(\"Use train data:\", PATH_TRAIN)\n",
    "print(\"Use test  data:\", PATH_TRAIN)\n",
    "\n",
    "train_data = pd.read_csv(PATH_TRAIN)\n",
    "test_data = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recoginize categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Restaurants' 'Nightlife' 'Shopping']\n"
     ]
    }
   ],
   "source": [
    "categories = train_data['category'].unique()\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that there are three categories in the data set, they are: `['Restaurants' 'Nightlife' 'Shopping']`.\n",
    "\n",
    "Then, we transform this column into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: category, dtype: int32\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: category, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "categories_type = CategoricalDtype(categories = categories)\n",
    "train_data['category'] = train_data['category'].astype(categories_type).cat.codes.astype('long')\n",
    "test_data['category'] = test_data['category'].astype(categories_type).cat.codes.astype('long')\n",
    "print(train_data['category'].head(), \"\\n\", test_data['category'].head(), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes process\n",
    "We start our Naive Bayes process.\n",
    "\n",
    "Firstly, we should build training and testing dataframe variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data['category']\n",
    "train_x = train_data['review']\n",
    "\n",
    "test_y = test_data['category']\n",
    "test_x = test_data['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to build a vector of word counts. Use built in class `CountVectorizer`. And transform original data into vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = CountVectorizer()\n",
    "train_x = vector.fit_transform(train_x).toarray()\n",
    "test_x = vector.transform(test_x).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other attributes also need to be considered. We merge these data into training and testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.append(train_data[['latitude', 'longitude', 'mean_checkin_time']], train_x, axis=1)\n",
    "test_x = np.append(test_data[['latitude', 'longitude', 'mean_checkin_time']], test_x, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already built our training and testing data set.\n",
    "\n",
    "Lastly, we could classify texts by using Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how many correct prediction we have made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532467532467533"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About $75.3%$ of the entire data set has been classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Optimization"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6adee2de74d267f267a666c0e4ee6c85309d51fbc20ddd8fabddd56db54bc85"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
