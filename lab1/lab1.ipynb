{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "## Task 1 Naive Bayes\n",
    "### Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use train data: d:\\Windows\\Documents\\Code\\conda\\machine-learning-lab\\lab1\\train.csv\n",
      "Use test  data: d:\\Windows\\Documents\\Code\\conda\\machine-learning-lab\\lab1\\train.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "PATH_ROOT = os.getcwd()\n",
    "PATH_TRAIN = os.path.join(PATH_ROOT, 'train.csv')\n",
    "PATH_TEST = os.path.join(PATH_ROOT, 'test.csv')\n",
    "\n",
    "print(\"Use train data:\", PATH_TRAIN)\n",
    "print(\"Use test  data:\", PATH_TRAIN)\n",
    "\n",
    "train_data = pd.read_csv(PATH_TRAIN)\n",
    "test_data = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recoginize categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Restaurants' 'Nightlife' 'Shopping']\n"
     ]
    }
   ],
   "source": [
    "categories = train_data['category'].unique()\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that there are three categories in the data set, they are: `['Restaurants' 'Nightlife' 'Shopping']`.\n",
    "\n",
    "Then, we transform this column into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: category, dtype: int32\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: category, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "categories_type = CategoricalDtype(categories = categories)\n",
    "train_data['category'] = train_data['category'].astype(categories_type).cat.codes.astype('long')\n",
    "test_data['category'] = test_data['category'].astype(categories_type).cat.codes.astype('long')\n",
    "print(train_data['category'].head(), \"\\n\", test_data['category'].head(), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes process\n",
    "We start our Naive Bayes process.\n",
    "\n",
    "Firstly, we should build training and testing dataframe variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data['review']\n",
    "train_y = train_data['category']\n",
    "\n",
    "test_x = test_data['review']\n",
    "test_y = test_data['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to build a vector of word counts. Use built in class `CountVectorizer`. And transform original data into vector. For test variables, we use the same methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = CountVectorizer()\n",
    "train_x = vector.fit_transform(train_x).toarray()\n",
    "test_x = vector.transform(test_x).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other attributes like `mean_checkin_time` also need to be considered. We merge these data into training and testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.append(train_data[['latitude', 'longitude', 'mean_checkin_time']], train_x, axis=1)\n",
    "test_x = np.append(test_data[['latitude', 'longitude', 'mean_checkin_time']], test_x, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already built our training and testing data set.\n",
    "\n",
    "Lastly, we could classify texts by using Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how many correct prediction we have made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532467532467533"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "About $75.3%$ of the entire data set has been classified correctly. However, this is the simplest model. We could build a more complex model to classify these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 Model improving\n",
    "Maybe we should use other Naive Bayes model after using `GaussianNB`.\n",
    "\n",
    "### `BernoulliNB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253968253968254"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector2 = CountVectorizer()\n",
    "train_x2 = train_data['review']\n",
    "train_y2 = train_data['category']\n",
    "train_x2 = vector2.fit_transform(train_x2).toarray()\n",
    "train_x2 = np.append(train_data[['latitude', 'longitude', 'mean_checkin_time']], train_x2, axis=1)\n",
    "nb2 = BernoulliNB()\n",
    "nb2.fit(train_x2, train_y2)\n",
    "\n",
    "test_x2 = test_data['review']\n",
    "test_y2 = test_data['category']\n",
    "test_x2 = vector2.transform(test_x2).toarray()\n",
    "test_x2 = np.append(test_data[['latitude', 'longitude', 'mean_checkin_time']], test_x2, axis=1)\n",
    "nb2.score(test_x2,test_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MultinomialNB`.\n",
    "\n",
    "Because `MultinomialNB` cannot accept negative values, we tries to remove `latitude` and `longitude` attributes from our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701298701298701"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector3 = CountVectorizer()\n",
    "train_x3 = train_data['review']\n",
    "train_y3 = train_data['category']\n",
    "train_x3 = vector3.fit_transform(train_x3).toarray()\n",
    "train_x3 = np.append(train_data[['mean_checkin_time']], train_x3, axis=1)\n",
    "nb3 = MultinomialNB()\n",
    "nb3.fit(train_x3, train_y3)\n",
    "\n",
    "test_x3 = test_data['review']\n",
    "test_y3 = test_data['category']\n",
    "test_x3 = vector3.transform(test_x3).toarray()\n",
    "test_x3 = np.append(test_data[['mean_checkin_time']], test_x3, axis=1)\n",
    "nb3.score(test_x3,test_y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "After verification, use `MultinomialNB` is a better model. The $87.0%$ of accuracy is far better than other models.\n",
    "\n",
    "Some further tries could be done. For example, we can make `latitude` and `longitude` positive. However, that didn't changed the results. So we can infer that `latitude` and `longitude` have low association with results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 Adding attributes\n",
    "Note that the `CountVectorizer` can ignore some words that appear too uncommon, and whether words show can be regarded as a binary value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8961038961038961"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector4 = CountVectorizer(min_df=0.001, binary=True)\n",
    "train_x4 = train_data['review']\n",
    "train_y4 = train_data['category']\n",
    "train_x4 = vector4.fit_transform(train_x4).toarray()\n",
    "train_x4 = np.append(train_data[['mean_checkin_time']], train_x4, axis=1)\n",
    "nb4 = MultinomialNB()\n",
    "nb4.fit(train_x4, train_y4)\n",
    "\n",
    "test_x4 = test_data['review']\n",
    "test_y4 = test_data['category']\n",
    "test_x4 = vector4.transform(test_x4).toarray()\n",
    "test_x4 = np.append(test_data[['mean_checkin_time']], test_x4, axis=1)\n",
    "nb4.score(test_x4,test_y4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "After adding attributes, we got a $89.6%$ correct rate. It did an improvement by setting ignore words and regarding whether words show as a binary value."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6adee2de74d267f267a666c0e4ee6c85309d51fbc20ddd8fabddd56db54bc85"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
